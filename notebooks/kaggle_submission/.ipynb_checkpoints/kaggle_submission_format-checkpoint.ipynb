{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COVID-19 Open Research Dataset Challenge - What do we know about vaccines and therapuetics?\n",
    "The following questions were analysed specifically: \n",
    "- Effectiveness of drugs being developed and tried to treat COVID-19 patients.\n",
    "  - Clinical and bench trials to investigate less common viral inhibitors against COVID-19 such as naproxen, clarithromycin, and minocyclinethat that may exert effects on viral replication.\n",
    "- Methods evaluating potential complication of Antibody-Dependent Enhancement (ADE) in vaccine recipients.\n",
    "- Exploration of use of best animal models and their predictive value for a human vaccine.\n",
    "- Capabilities to discover a therapeutic (not vaccine) for the disease, and clinical effectiveness studies to discover therapeutics, to include antiviral agents.\n",
    "- Efforts targeted at a universal coronavirus vaccine.\n",
    "- Efforts to develop animal models and standardize challenge studies\n",
    "- Assays to evaluate vaccine immune response and process development for vaccines, alongside suitable animal models (in conjunction with therapeutics)\n",
    "\n",
    "## Our approach - Creating a timeline visualizing the progress of vaccines/cures on COVID-19 and other similar viral diseases.\n",
    "Our goal is to create an intuitive visualization of the progress of research on vaccines and therapuetics regarding COVID-19. Not only is this useful for professional researchers in having a quick overview of the clinical trial stages of each investigated vaccine/therapeutic, but also for the public, to have a better understanding of the time frame for which to expect a cure or solution. We decided to create vizualizations of research progress of other virusses as well as COVID-19, to get a better picture of the timescale and ammount of research that goes into making a vaccine or therapeutics.\n",
    "\n",
    "Several steps were taken to create the visualizations:\n",
    "1. Load and preprocess the data:\n",
    "    - lemmatize all texts and remove stopwords\n",
    "2. Select papers containing words relevant to the research question\n",
    "    - using either string pattern matching or word embeddings\n",
    "    - relevant words were manually selected based on the research questions and indicativaty of clinical stage trial (e.g. mouse vs human test subject, words expressing certainty etc.)\n",
    "3. Extract keywords from selected papers\n",
    "    - TODO: write how we do this @Simon, @Silvan\n",
    "4. Extract links between selected papers\n",
    "    - TODO: write how we do this @Levi @Miguel\n",
    "5. Visualize extracted papers, links and summaries\n",
    "    - TODO: explain how (after we know how) @Levi @Gloria\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.a Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# TODO: write your imports here\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.b Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# As kaggle only allows notebook submissions, all functions should be in the notebook. Just copy your functions and paste them here.\n",
    "\n",
    "class Dataset:\n",
    "    \"\"\"COVID19 Papers Dataset\n",
    "    \n",
    "    Attributes:\n",
    "        data_dir: string location where data files can be found.\n",
    "        paper_ids: list containing str of unique pdf ids for each paper. \n",
    "            ie. ['sha1', 'sha2', 'sha3', ...]\n",
    "        titles: list containing str titles of papers. \n",
    "            ie. ['title1', 'title2', 'title3', ...]\n",
    "        abstracts: list containing str abstracts of each paper. \n",
    "            ie. ['abstract1', 'abstract2', 'abstract3', ...]\n",
    "        n_paragraphs: list of integers specifying the amount of paragraphs in each paper. \n",
    "            ie. [n1, n2, n3, ...]\n",
    "        contents: nested list containing contents of paper; contents of each paper stored in a list of strings containing paragraphs. \n",
    "            ie. [['paper1_p1', 'paper1_p2', ...], ['paper2_p1', 'paper2_p2', ...], ...]\n",
    "    \n",
    "    Attributes are initially empty. To populate data, run class method of load_data().\n",
    "    \n",
    "    Usage:\n",
    "        # declare directory where data is stored\n",
    "        data_dir = '/kaggle/input/CORD-19-research-challenge'  \n",
    "        data = Dataset(data_dir)\n",
    "        data.load_data()\n",
    "        \n",
    "        # get attributes\n",
    "        data.paper_ids\n",
    "        data.titles\n",
    "        ...\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir:str):\n",
    "        # init lists to store data\n",
    "        self.data_dir = data_dir\n",
    "        self.paper_ids = []\n",
    "        self.titles = []\n",
    "        self.abstracts = []\n",
    "        self.n_paragraphs = []\n",
    "        self.contents = []\n",
    "        \n",
    "        print(\"[INFO] Empty Dataset object created.\")\n",
    "        \n",
    "    @property\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the total number of samples.\"\"\"\n",
    "        return f\"Dataset instance has {len(self.paper_ids)} samples\"\n",
    "    \n",
    "    def load_data(self):\n",
    "        \"\"\"Load data from dataset data directory.\"\"\"\n",
    "        data_dir = str(self.data_dir)\n",
    "        subdir = [x for x in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir,x))]\n",
    "        \n",
    "        initial_samples = len(self.paper_ids)\n",
    "        \n",
    "        print(f\"[INFO] Loading data from {data_dir}...\")\n",
    "        # loop through folders with json files\n",
    "        for folder in subdir:\n",
    "#             path = os.path.join(data_dir,folder, folder)\n",
    "            path = os.path.join(data_dir,folder, folder, 'pdf_json')\n",
    "            # loop through json files and scrape data\n",
    "            for file in os.listdir(path):\n",
    "                file_path = os.path.join(path, file)\n",
    "                \n",
    "                # open file only if it is a file\n",
    "                if os.path.isfile(file_path):\n",
    "                    with open(file_path) as f:\n",
    "                        data_json = json.load(f)\n",
    "                        self.paper_ids.append(data_json['paper_id'])\n",
    "                        self.titles.append(data_json['metadata']['title'])\n",
    "\n",
    "                        # combine abstract texts / process\n",
    "                        combined_str = ''\n",
    "                        for text in data_json['abstract']:\n",
    "                            combined_str += text['text'].lower()\n",
    "\n",
    "                        self.abstracts.append(combined_str)\n",
    "\n",
    "                        # take only text part for content\n",
    "                        paragraphs = []\n",
    "                        content = data_json['body_text']\n",
    "\n",
    "                        for paragraph in content:\n",
    "                            paragraphs.append(paragraph['text'].lower())\n",
    "\n",
    "                        self.n_paragraphs.append(len(content))\n",
    "                        self.contents.append(paragraphs) \n",
    "                else:\n",
    "                    print('[WARNING]', file_path, 'not a file. Check pointed path directory in load_data().')\n",
    "        \n",
    "        end_samples = len(self.paper_ids)\n",
    "        loaded_samples = end_samples - initial_samples\n",
    "        print(f\"[INFO] Data loaded into dataset instance. {loaded_samples} samples added. | Start amount = {initial_samples}; End amount = {end_samples}\")\n",
    "\n",
    "# def load_data(path):\n",
    "#     #TODO @Kwan: function for loading data goes here\n",
    "#     return data\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    #TODO @Kwan: function for removing stopwords\n",
    "    return text_without_stopwords\n",
    "\n",
    "def lemmatize(text):\n",
    "    #TODO @Kwan: function for lemmatizing text\n",
    "    return lemmatized_text\n",
    "\n",
    "def select_papers(data, virus_strings, clinical_stage_strings):\n",
    "    #TODO @Pooja @Miguel: select papers based on relevant_strings\n",
    "\n",
    "    # output: selected papers + the strings that were found in these papers\n",
    "    selected_papers['found_substrings'] = found_substrings\n",
    "    return selected_papers\n",
    "\n",
    "def extract_keywords(text):\n",
    "    # TODO @Simon @Silvan: extract keywords\n",
    "    return keywords\n",
    "\n",
    "def extract_links(data):\n",
    "    # TODO @Levi @Miguel: extract links between papers    \n",
    "    return links\n",
    "\n",
    "def visualize_data(data,keywords,summaries):\n",
    "    #TODO @Levi @Kwan: visualize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.c Relevant strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patterns defining different coronavirus diseases\n",
    "virus_strings = {'covid-19':['COVID-19','SARS-CoV-2',\\\n",
    "                 'coronavirus disease','severe acute \\\n",
    "                 respiratory syndrome coronavirus 2'], \\\n",
    "                'common cold':['common cold', 'human coronavirus \\\n",
    "                229E', 'human coronavirus OC43', '229E', 'OC43'] \\\n",
    "                'SARS-CoV (2003)':['SARS-CoV'], 'HCoV NL63 (2004)':['HCoV NL63'], \\\n",
    "                'HKU1 (2005)': ['HKU1'], 'MERS-CoV (2012)':['MERS-CoV']}\n",
    "\n",
    "# patterns defining different stages of clinical trials:\n",
    "# if this works I will put it in a txt file and load it here\n",
    "\n",
    "clinical_stage_strings = {}\n",
    "clinical_stage_strings['preclinical'] = 'Preclinical trial/study/studies/development nonclinical studies \\\n",
    "laboratory animals prior to moving to the phase one trials \\\n",
    "adverse effects and immunogenicity vaccine safety and the immunological response to the drug, such as toxicity, \\\n",
    "toxic effects at all possible dosage levels and the interactions with the immune system. \\\n",
    "preclinical protocol in hopes to more accurately determine drug reactions in humans. \\\n",
    "transgenic animals, genetically modified animals, Typically, in drug development studies animal testing involves two species. The most commonly used models are murine and canine, although primate and porcine are also used. \\\n",
    "mice, ferrets, monkey, in vitro, pig, dog, This data allows researchers to allometrically estimate a safe starting dose of the drug for clinical trials in humans. \\\n",
    "Importantly, the regulatory guidelines of FDA, EMA, and other similar international and regional authorities usually require safety testing in at least two mammalian species, including one non-rodent species, prior to human trials authorization \\\n",
    "Deciding whether a drug is ready for clinical trials (the so-called move from bench to bedside) involves extensive preclinical studies that yield preliminary efficacy, toxicity, pharmacokinetic and safety information. Wide doses of the drug are tested using in vitro (test tube or cell culture) and in vivo (animal) experiments, and it is also possible to perform in silico profiling using computer models of the drug–target interactions. \\\n",
    "Much like for clinical trials, there are certain types of trials that have to be done, such as toxicology studies in most cases, and other trials that are specific to the particular study compound or question. Understanding that the goal of preclinical trials is to move into the clinical stage is key and the studies should be designed around that goal.'\n",
    "\n",
    "clinical_stage_strings['phase_0'] = 'Phase 0 phase zero (optional) trial/study \\\n",
    "Phase 0 trials are optional first-in-human trials. Single subtherapeutic doses of the study drug or treatment are given to a small number of subjects (typically 10 to 15) to gather preliminary data on the agent\\'s pharmacodynamics (what the drug does to the body) and pharmacokinetics (what the body does to the drugs).[35] For a test drug, the trial documents the absorption, distribution, metabolization, and removal (excretion) \\\n",
    "of the drug, and the drug\\'s interactions within the body, to confirm that these appear to be as expected. \\\n",
    "Phase 0 involves exploratory, first-in-human (FIH) trials that are run according to FDA guidelines. Also called human microdose studies, they have single sub-therapeutic doses given to 10 to 15 subjects and yield pharmacokinetic data or help with imaging specific targets without introducing pharmacological effects.'\n",
    "\n",
    "clinical_stage_strings['phase_1'] = 'Phase 1 phase I trial/study / Early phase clinical trial \\\n",
    "Screening for safety Often are first-in-person trials. Testing within a small group of people (typically 20–80) to evaluate safety, determine safe dosage ranges, and identify side effects. \\\n",
    "The following stage in vaccine trials is the phase one study, which consists of introducing the drug into the human population. \\\n",
    "A vaccine trial might involve forming two groups from the target population. For example, from the set of trial subjects, each subject may be randomly assigned to receive either a new vaccine or a \"control\" treatment: The control treatment may be a placebo, or an adjuvant-containing cocktail, or an established vaccine (which might be intended to protect against a different pathogen). \\\n",
    "After the administration of the vaccine or placebo, the researchers collect data on antibody production, on health outcomes (such as illness due to the targeted infection or to another infection). This data is summarized as a statistic, which is used to estimate the protective efficacy of the vaccine. Then, following the trial protocol, the specified statistical test is performed to gauge the statistical significance of the observed differences in the outcomes between the treatment and control groups. \\\n",
    "Side effects of the vaccine are also noted, and these too contribute to the decision on whether to license it. \\\n",
    "One very typical version of phase one studies in vaccines involves an escalation study, which is used in mainly medicinal research trials. The drug is introduced into a small cohort of healthy volunteers. Vaccine escalation studies aim to minimize chances of serious adverse effects (SAE) by slowly increasing the drug dosage or frequency.[3] The first level of an escalation study usually has two or three groups of around 10 healthy volunteers. \\\n",
    "Each subgroup receives the same vaccine dose, which is the expected lowest dose necessary to invoke an immune response (the main goal in a vaccine - to create immunity). New subgroups can be added to experiment with a different dosing regimen as long as the previous subgroup did not experience SAEs. There are variations in the vaccination order that can be used for different studies. For example, the first subgroup could complete the entire regimen before the second subgroup starts or the second can begin \\\n",
    "before the first ends as long as SAEs were not detected.[3] The vaccination schedule will vary depending on the nature of the drug (i.e. the need for a booster or several doses over the course of short time period). Escalation studies are ideal for minimizing risks for SAEs that could occur with less controlled and divided protocols. \\\n",
    "They are primarily designed to assess the safety and tolerability of a drug, but the pharmacokinetics and, if possible, the pharmacodynamics are also measured. \\\n",
    "The typical Phase I trial has a single ascending dose (SAD) design, meaning that subjects are dosed in small groups called cohorts. Each member of a cohort might receive a single dose of the study drug or a placebo. A very low dose is used for the first cohort. The dose is then escalated in the next cohort if safety and tolerability allow. \\\n",
    "Dose escalation is stopped when maximum tolerability and/or maximum exposure is reached. \\\n",
    "SAD studies are usually followed by multiple ascending dose (MAD) studies, which have a very similar design, with cohorts and escalating doses. The only difference is that the subjects receive multiple doses of the study drug or placebo. \\\n",
    "While safety and tolerability are still important endpoints, the multiple dose setting often allows first investigations of the pharmacodynamic effects in addition to the pharmacokinetics. \\\n",
    "Finally, food effect studies are often conducted to investigate the potential impact of food intake on the absorption of the drug. \\\n",
    "new vaccine or a \"control\" treatment \\\n",
    "The control treatment may be a placebo, or an adjuvant-containing cocktail, or an established vaccine \\\n",
    "infection which is used to estimate the protective efficacy of the vaccine \\\n",
    "Side effects of the vaccine are also noted, and these too contribute to the decision on whether to license it \\\n",
    "escalation study Vaccine escalation studies aim to minimize chances of serious adverse effects (SAE) by slowly increasing the drug dosage or frequency. \\\n",
    "expected lowest dose necessary to invoke an immune response dosing regimen'\n",
    "'\n",
    "\n",
    "clinical_stage_strings['phase_2'] = 'Phase 2 phase II trial/study / Early phase clinical trial \\\n",
    "Establishing the preliminary efficacy of the drug, usually against a placebo \\\n",
    "Testing with a larger group of people (typically 100–300) to determine efficacy and   to further evaluate its safety. \\\n",
    "The transition to phase two relies on the immunogenic and toxicity results from phase one and the small cohort of healthy volunteers.[4] Phase two will consist of more healthy volunteers in the vaccine target population (~hundreds of people) to determine reactions in a more diverse set of humans and test different schedules. \\\n",
    "Phase II trials are performed on larger groups of patients and are designed to assess the efficacy of the drug and to continue the Phase I safety assessments. Most importantly, Phase II clinical studies help to establish therapeutic doses for the large-scale Phase III studies. \\\n",
    "Phase II studies are sometimes divided into Phases IIA and IIB. Phase IIA is designed to assess dosing requirements whereas Phase IIB focuses on drug efficacy. \\\n",
    "In addition, a treatment study with several different doses of the compound in comparison with a placebo and/or an active comparator over a treatment duration of 12 to 16 weeks is usually an essential part of the Phase II program.'\n",
    "\n",
    "clinical_stage_strings['phase_3'] = 'Phase 3 phase III trial/study / Late phase clinical trial \\\n",
    "Final confirmation of safety and efficacy Testing with large groups of people (typically 1,000–3,000) to confirm its efficacy,\tevaluate its effectiveness, monitor side effects, compare it to commonly used treatments, and collect information that will allow it to be used safely. \\\n",
    "Similarly, phase three trials continue to monitor toxicity, immunogenicity, and SAEs on a much larger scale.[4] The vaccine must be shown to be safe and effective in natural disease conditions before being submitted for approval and then general production. In the United States, the Food and Drug Administration (FDA) is responsible for approving vaccines.[5] \\\n",
    "Phase III trials are randomized controlled multicentre trials and provide most of the long-term safety data. Phase III trials investigate the efficacy and safety of a new drug over 6 to 12 months or longer in a large patient population (several hundred patients or more) under conditions that reflect daily clinical life much more closely than the Phase I or II trials and allow evaluation of the overall benefit-risk relationship of the drug. These trials are usually conducted on an outpatient basis with no in-house days and include an active comparator \\\n",
    "Phase IIIA studies are used for the approval of the drug from the appropriate regulatory agencies (known as Pivotal study). \\\n",
    "Phase IIIB studies are often performed to obtain additional safety data or to support publication, marketing claims (label extension) or to prepare launch for the drug.'\n",
    "\n",
    "clinical_stage_strings['phase_4'] = 'Phase 4 phase IV trial/study / Late phase clinical trial \\\n",
    "    Safety studies during sales. Postmarketing studies delineate risks, benefits, and optimal use. As such, they are ongoing during the drug\\'s lifetime of active medical use \\\n",
    "    Phase four trials are typically monitor stages that collect information continuously on vaccine usage, adverse effects, and long-term immunity.[5] \\\n",
    "    Phase IV trials are also known as post-marketing surveillance trials involving safety surveillance (pharmacovigilance) and ongoing technical support after approval. \\\n",
    "    There are multiple observational designs and evaluation schemes that can be used in Phase IV studies to assess the effectiveness, cost-effectiveness, and safety of an intervention in real-world settings. \\\n",
    "    This could entail the drug being tested in a certain new population (e.g. pregnant women). The safety surveillance is designed to detect any rare or long-term adverse effects over a much larger patient population and longer time period.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load and Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path to data\n",
    "path = '../input/CORD-19-research-challenge'\n",
    "\n",
    "# load data in pandas dataframe\n",
    "data = load_data(path)\n",
    "\n",
    "# add colums with processed text (no stopwords, lemmatized)\n",
    "processed_text = data['text'].apply(remove_stopwords())\n",
    "processed_text = processed_text.apply(lemmatize())\n",
    "\n",
    "# append processed text to data\n",
    "data['processed_text'] = processed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Select papers containing words relevant to the research question "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_papers = select_papers(data, virus_strings, clinical_stage_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Extract keywords from selected papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = extract_keywords(selected_papers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Extract links between selected papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "(0, 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (0, 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5f2894e9f20f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2994\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2995\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2996\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2997\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_index_shared_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"get_indexer\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (0, 0)"
     ]
    }
   ],
   "source": [
    "paper_links = extract_links(selected_papers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Visualize extracted papers, links and summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_data(selected_papers,keywords,paper_links)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
